#分布式事务（还需要更新）

一般来说，大部分服务基本上，只要设计的好，就可以把数据存储在同一个数据库中，本地事务即可解决。
毕竟分布式事务的成本，相对于中小服务来说，要比冗余字段、代码冗余要大得多。
只有业务发展到，确实复杂到多个业务系统调用更新数据时，考虑分布式事务才有有意义。
一般是业务系统相互调用，更新数据的场景下，才会出现分布式事务的需求。
目前，业界主要解决方案是两阶段提交、补偿事务（TCC）、本地消息表和mq介入三种方案


-------------
## 两阶段提交

- 第一阶段-原理是相关的多个库，先执行sql语句事务（只是执行，还未提及事务）
- 第二阶段-监管者得到相关多个库sql语句执行的事务结果，全部成功时，通知全部提交（有一个失败都要全部回滚)

    缺点：
        1 容易成为服务瓶颈，因为事务提交需要等待业务发生的sql事务执行结果（如果有一个卡着了呢，就会导致一直等待)
        2 容易出现数据不一致的问题，主要出现在第二阶段，如果有一部分事务提交成功了，有一部事务提交分失败了。。。，就完犊子了，数据不一致了
-------------

## 补偿事务（TCC）

TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。
它分为三个阶段：

    - Try 阶段主要是对业务系统做检测及资源预留
    - Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。
    - Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。
-------------

## 本地消息表

   本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。
在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。
之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。
在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。

优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。
缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。
-------------

## mq介入一致性

   有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。
以阿里的 RocketMQ 中间件为例，其思路大致为：
    第一阶段Prepared消息，会拿到消息的地址。 
    第二阶段执行本地事务，
    第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。
也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。
如果确认消息发送失败了RocketMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。

优点： 实现了最终一致性，不需要依赖本地数据库事务。
缺点： 实现难度大，主流MQ不支持，RocketMQ事务消息部分代码也未开源。
-------------
